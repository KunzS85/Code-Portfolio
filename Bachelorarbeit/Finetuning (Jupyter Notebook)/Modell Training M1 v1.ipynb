{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"NTC6g8BIJt9F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652357877147,"user_tz":-120,"elapsed":20553,"user":{"displayName":"Sebastian Kunz","userId":"15503187521722283201"}},"outputId":"1a59c426-fc1f-4513-d346-3d0b85749dba"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install transformers\n","!pip install numpy \n","!pip install pandas\n","!pip install sklearn\n","!pip install torch \n","!pip install sklearn\n","!pip install seaborn\n","!pip install matplotlib\n","!pip install json\n","!pip install fast_ml"],"metadata":{"id":"VwpAtKR0Jnx_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652357916597,"user_tz":-120,"elapsed":36916,"user":{"displayName":"Sebastian Kunz","userId":"15503187521722283201"}},"outputId":"3150541a-7a7d-4211-ff74-3fbe8e4d4cde"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 4.1 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 60.4 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 71.2 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 44.1 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n","\u001b[K     |████████████████████████████████| 84 kB 2.7 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=0e58dd3f29cdf359d0260483bec6b4f7e8db6c1826e90776bb25d45c1aaa7080\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n","Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n","Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n","Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.3.5)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1)\n","Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2)\n","Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.21.6)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (3.0.8)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.4.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.2->seaborn) (4.2.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.8)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.2)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n","\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for json\u001b[0m\n","Collecting fast_ml\n","  Downloading fast_ml-3.68-py3-none-any.whl (42 kB)\n","\u001b[K     |████████████████████████████████| 42 kB 656 kB/s \n","\u001b[?25hInstalling collected packages: fast-ml\n","Successfully installed fast-ml-3.68\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"aodl1OpDRYKV","executionInfo":{"status":"ok","timestamp":1652357929898,"user_tz":-120,"elapsed":7056,"user":{"displayName":"Sebastian Kunz","userId":"15503187521722283201"}}},"outputs":[],"source":["import numpy as np #Für Matrizen\n","import pandas as pd #Für Dataframes\n","import re\n","from typing import List, Any, Set, Dict, Tuple, Optional\n","from ast import literal_eval\n","import json # load json module\n","from sklearn.model_selection import train_test_split\n","import torch\n","from tqdm.notebook import tqdm\n","from torch.utils.data import TensorDataset\n","from transformers import BertTokenizer, AutoTokenizer\n","from transformers import BertForSequenceClassification\n","from fast_ml.model_development import train_valid_test_split"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"QN_Zjy0GRYBp","executionInfo":{"status":"ok","timestamp":1652357933569,"user_tz":-120,"elapsed":358,"user":{"displayName":"Sebastian Kunz","userId":"15503187521722283201"}}},"outputs":[],"source":["dict_name = \"l_dict_m1\"\n","json_dir = f'/content/drive/MyDrive/{dict_name}.json'"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1333,"status":"ok","timestamp":1652357938435,"user":{"displayName":"Sebastian Kunz","userId":"15503187521722283201"},"user_tz":-120},"id":"12Ct7lpnRX_s","outputId":"802674d4-5a49-4a8d-8bba-e211e8496e87"},"outputs":[{"output_type":"stream","name":"stdout","text":["SNOMED CT NOT SNOMED CT 2\n","{'SNOMED CT': {'name': '', 'synonym': '', 'code': 'SNOMED CT', 'index': 0}, 'NOT SNOMED CT': {'name': '', 'synonym': '', 'code': 'NOT SNOMED CT', 'index': 1}}\n"]}],"source":["with open(json_dir) as jsonFile:\n","    labels_Input = json.load(jsonFile)\n","    jsonFile.close()\n","print(max(labels_Input), min(labels_Input), len(labels_Input))\n","print(labels_Input)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1652357940948,"user":{"displayName":"Sebastian Kunz","userId":"15503187521722283201"},"user_tz":-120},"id":"mcxe1TNSRX9x","outputId":"bc9718b8-6ff4-445f-cc5c-da8661b99d0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["2\n"]}],"source":["labels_Output = {}\n","for k, v in labels_Input.items():\n","    labels_Output[v[\"index\"]] = {\n","            \"name\": v[\"name\"],\n","            \"code\": k,\n","            \"index\": v[\"index\"]\n","            } \n","print(len(labels_Output))"]},{"cell_type":"markdown","metadata":{"id":"USiHYqIU3K-E"},"source":["**Trainingsdaten vorbereiten**"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"NbUy8_BQ3Yl7","executionInfo":{"status":"ok","timestamp":1652357945599,"user_tz":-120,"elapsed":5,"user":{"displayName":"Sebastian Kunz","userId":"15503187521722283201"}}},"outputs":[],"source":["excel_path = '/content/drive/MyDrive/train_data.xlsx'\n","sheet_name = \"labeled_dataset1\""]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Maqto3fhRYFy","outputId":"ef81b89a-43d0-42bc-f16e-7c0ca269e86f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652357981176,"user_tz":-120,"elapsed":33791,"user":{"displayName":"Sebastian Kunz","userId":"15503187521722283201"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["                                                     Text      Label\n","0                          Excision of lesion of patella   SNOMED CT\n","1                           Excision of lesion of patella  SNOMED CT\n","2           Local excision of lesion or tissue of patella  SNOMED CT\n","3                   Structure of posterior carpal region   SNOMED CT\n","4                                 Posterior carpal region  SNOMED CT\n","...                                                   ...        ...\n","464496  intestinal continuity according to Hartmann\\n1...  SNOMED CT\n","464497  intestinal continuity according to Hartmann\\n1...  SNOMED CT\n","464498  intestinal continuity according to Hartmann\\n1...  SNOMED CT\n","464499  intestinal continuity according to Hartmann\\n1...  SNOMED CT\n","464500  intestinal continuity according to Hartmann\\n1...  SNOMED CT\n","\n","[464501 rows x 2 columns]\n","464501\n"]}],"source":["df = pd.read_excel(excel_path, sheet_name, index_col=None)\n","df = df.astype({'Label': str})\n","print(df)\n","print(len(df))"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"to37VWJpRYDo","outputId":"e6746e6a-3830-4828-dac0-4a71fe55de9b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652357983329,"user_tz":-120,"elapsed":380,"user":{"displayName":"Sebastian Kunz","userId":"15503187521722283201"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["SNOMED CT        241371\n","NOT SNOMED CT    223130\n","Name: Label, dtype: int64"]},"metadata":{},"execution_count":9}],"source":["df['Label'].value_counts()"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"MlKOn-kcRX7k","outputId":"4765b297-2443-4871-b088-aab97590403b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652358011914,"user_tz":-120,"elapsed":23686,"user":{"displayName":"Sebastian Kunz","userId":"15503187521722283201"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["                                                     Text      Label  \\\n","0                          Excision of lesion of patella   SNOMED CT   \n","1                           Excision of lesion of patella  SNOMED CT   \n","2           Local excision of lesion or tissue of patella  SNOMED CT   \n","3                   Structure of posterior carpal region   SNOMED CT   \n","4                                 Posterior carpal region  SNOMED CT   \n","...                                                   ...        ...   \n","464496  intestinal continuity according to Hartmann\\n1...  SNOMED CT   \n","464497  intestinal continuity according to Hartmann\\n1...  SNOMED CT   \n","464498  intestinal continuity according to Hartmann\\n1...  SNOMED CT   \n","464499  intestinal continuity according to Hartmann\\n1...  SNOMED CT   \n","464500  intestinal continuity according to Hartmann\\n1...  SNOMED CT   \n","\n","        label_code  \n","0                0  \n","1                0  \n","2                0  \n","3                0  \n","4                0  \n","...            ...  \n","464496           0  \n","464497           0  \n","464498           0  \n","464499           0  \n","464500           0  \n","\n","[464501 rows x 3 columns]\n"]}],"source":["label_code = []\n","code_fails = []\n","for index, row in df.iterrows():\n","    if row[\"Label\"] in labels_Input:\n","        label_code.append(labels_Input[row[\"Label\"]][\"index\"])\n","    else:\n","        label_code.append(labels_Input[\"-1\"][\"index\"])\n","\n","df['label_code'] = label_code\n","print(df)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"FF5kZuoARX5o","outputId":"ce24d463-3648-45a9-e6fb-4a1bc932b466","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652358020516,"user_tz":-120,"elapsed":393,"user":{"displayName":"Sebastian Kunz","userId":"15503187521722283201"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["0 1 2\n"]}],"source":["labels_Output = {}\n","for k, v in labels_Input.items():\n","    labels_Output[v[\"index\"]] = {\n","      \"name\": v[\"name\"],\n","      \"code\": k,\n","      \"index\": v[\"index\"]\n","  } \n","\n","print(min(labels_Output), max(labels_Output), len(labels_Output))"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Tik91FfOfv3h","outputId":"710d7e7d-6866-46bc-f21b-3e6b1a79924e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652358024137,"user_tz":-120,"elapsed":9,"user":{"displayName":"Sebastian Kunz","userId":"15503187521722283201"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    241371\n","1    223130\n","Name: label_code, dtype: int64"]},"metadata":{},"execution_count":12}],"source":["df['label_code'].value_counts()"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"GPg1s0vjRX1s","outputId":"7ff26df8-cdc7-4f00-b025-7e58a52570ba","colab":{"base_uri":"https://localhost:8080/","height":269},"executionInfo":{"status":"ok","timestamp":1652358029798,"user_tz":-120,"elapsed":1269,"user":{"displayName":"Sebastian Kunz","userId":"15503187521722283201"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                      Text\n","Label         label_code data_type        \n","NOT SNOMED CT 1          test        22267\n","                         train      178745\n","                         val         22118\n","SNOMED CT     0          test        24184\n","                         train      192855\n","                         val         24332"],"text/html":["\n","  <div id=\"df-e5500705-1119-4585-bda4-461a4b115bad\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th>Text</th>\n","    </tr>\n","    <tr>\n","      <th>Label</th>\n","      <th>label_code</th>\n","      <th>data_type</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">NOT SNOMED CT</th>\n","      <th rowspan=\"3\" valign=\"top\">1</th>\n","      <th>test</th>\n","      <td>22267</td>\n","    </tr>\n","    <tr>\n","      <th>train</th>\n","      <td>178745</td>\n","    </tr>\n","    <tr>\n","      <th>val</th>\n","      <td>22118</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">SNOMED CT</th>\n","      <th rowspan=\"3\" valign=\"top\">0</th>\n","      <th>test</th>\n","      <td>24184</td>\n","    </tr>\n","    <tr>\n","      <th>train</th>\n","      <td>192855</td>\n","    </tr>\n","    <tr>\n","      <th>val</th>\n","      <td>24332</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5500705-1119-4585-bda4-461a4b115bad')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e5500705-1119-4585-bda4-461a4b115bad button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e5500705-1119-4585-bda4-461a4b115bad');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}],"source":["X_train, y_train, X_valid, y_valid, X_test, y_test = train_valid_test_split(df, target = 'label_code', \n","                                                                            train_size=0.8, valid_size=0.1, test_size=0.1)\n","\n","df['data_type'] = ['not_set']*df.shape[0]\n","\n","df.loc[X_train.index.values, 'data_type'] = 'train'\n","df.loc[X_valid.index.values, 'data_type'] = 'val'\n","df.loc[X_test.index.values, 'data_type'] = 'test'\n","\n","df.groupby(['Label', 'label_code', 'data_type']).count()"]},{"cell_type":"markdown","metadata":{"id":"oRZfwJpp3Y9N"},"source":["**Training vorbereiten**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"elapsed":110810,"status":"ok","timestamp":1651593907051,"user":{"displayName":"Sebastian Kunz","userId":"15503187521722283201"},"user_tz":-120},"id":"TUItYZMrRXzX","outputId":"14724488-9521-4517-87a1-dc1f3a0bb0dc"},"outputs":[{"name":"stderr","output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"name":"stdout","output_type":"stream","text":["Encode Train Data.......\n","Encode Validation Data.......\n","Encode Test Data.......\n"]}],"source":["tokenizer = BertTokenizer.from_pretrained('dmis-lab/biobert-base-cased-v1.2')\n","\n","print(\"Encode Train Data.......\")\n","encoded_data_train = tokenizer.batch_encode_plus(\n","    df[df.data_type=='train'].Text.values, \n","    add_special_tokens=True, \n","    return_attention_mask=True, \n","    pad_to_max_length=True, \n","    max_length=512, \n","    return_tensors='pt'\n",")\n","print(\"Encode Validation Data.......\")\n","encoded_data_val = tokenizer.batch_encode_plus(\n","    df[df.data_type=='val'].Text.values, \n","    add_special_tokens=True, \n","    return_attention_mask=True, \n","    pad_to_max_length=True, \n","    max_length=512, \n","    return_tensors='pt'\n",")\n","print(\"Encode Test Data.......\")\n","encoded_data_test = tokenizer.batch_encode_plus(\n","    df[df.data_type=='test'].Text.values, \n","    add_special_tokens=True, \n","    return_attention_mask=True, \n","    pad_to_max_length=True, \n","    max_length=512, \n","    return_tensors='pt'\n",")\n","\n","input_ids_train = encoded_data_train['input_ids']\n","attention_masks_train = encoded_data_train['attention_mask']\n","labels_train = torch.tensor(df[df.data_type=='train'].label_code.values)\n","\n","input_ids_val = encoded_data_val['input_ids']\n","attention_masks_val = encoded_data_val['attention_mask']\n","labels_val = torch.tensor(df[df.data_type=='val'].label_code.values)\n","\n","input_ids_test = encoded_data_test['input_ids']\n","attention_masks_test = encoded_data_test['attention_mask']\n","labels_test = torch.tensor(df[df.data_type=='test'].label_code.values)\n","\n","dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n","dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n","dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3325,"status":"ok","timestamp":1651420189165,"user":{"displayName":"Sebastian Kunz","userId":"15503187521722283201"},"user_tz":-120},"id":"o5XlQDg4RXxQ","outputId":"7e90ee8e-b248-44f7-ee81-e64dd274ac2d"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.2 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = BertForSequenceClassification.from_pretrained('dmis-lab/biobert-base-cased-v1.2',\n","                                                      num_labels=len(labels_Input),\n","                                                      output_attentions=False,\n","                                                      output_hidden_states=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RFeYlEH5RXvD"},"outputs":[],"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","batch_size = 8\n","\n","dataloader_train = DataLoader(dataset_train, \n","                              sampler=RandomSampler(dataset_train), \n","                              batch_size=batch_size)\n","\n","dataloader_validation = DataLoader(dataset_val, \n","                                   sampler=SequentialSampler(dataset_val), \n","                                   batch_size=batch_size)\n","\n","dataloader_test = DataLoader(dataset_test, \n","                                   sampler=SequentialSampler(dataset_test), \n","                                   batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dE2WD0AIRXoS"},"outputs":[],"source":["from transformers import get_linear_schedule_with_warmup\n","from torch.optim import Adam\n","\n","optimizer = Adam(model.parameters(),\n","                  lr=1e-5, \n","                  eps=1e-8)\n","                  \n","epochs =  5\n","\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps=0,\n","                                            num_training_steps=len(dataloader_train)*epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-gQBGJPMRXgE"},"outputs":[],"source":["from sklearn.metrics import f1_score\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LgwbhAhZSa-W"},"outputs":[],"source":["def f1_score_func(preds, labels):\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return f1_score(labels_flat, preds_flat, average='weighted')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kNcG2SgoSa5I"},"outputs":[],"source":["import random\n","import torch\n","import numpy as np\n","\n","def evaluate(dataloader_val):\n","\n","    model.eval()\n","    \n","    loss_val_total = 0\n","    predictions, true_vals = [], []\n","    \n","    for batch in dataloader_val:\n","        \n","        batch = tuple(b.to(device) for b in batch)\n","        \n","        inputs = {'input_ids':      batch[0],\n","                  'attention_mask': batch[1],\n","                  'labels':         batch[2],\n","                 }\n","\n","        with torch.no_grad():        \n","            outputs = model(**inputs)\n","            \n","        loss = outputs[0]\n","        #print(loss)\n","        logits = outputs[1]\n","        #print(logits)\n","        loss_val_total += loss.item()\n","        #print(loss_val_total)\n","\n","        logits = logits.detach().cpu().numpy()\n","        #print(logits)\n","        label_ids = inputs['labels'].cpu().numpy()\n","        #print(label_ids)\n","\n","        #print(label_ids)\n","        predictions.append(logits)\n","        true_vals.append(label_ids)\n","\n","\n","    loss_val_avg = loss_val_total/len(dataloader_val) \n","    #print(predictions)\n","    #print(true_vals)\n","    predictions = np.concatenate(predictions, axis=0)\n","    true_vals = np.concatenate(true_vals, axis=0)\n","    #print(len(predictions))\n","    #print(len(true_vals))\n","\n","            \n","    return loss_val_avg, predictions, true_vals"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OlcQCoaCSayz"},"outputs":[],"source":["import random\n","import torch\n","import numpy as np\n","\n","def test(dataloader_test):\n","\n","    model.eval()\n","    \n","    predictions, true_vals = [], []\n","    \n","    for batch in dataloader_test:\n","        \n","        batch = tuple(b.to(device) for b in batch)\n","        \n","        inputs = {'input_ids':      batch[0],\n","                  'attention_mask': batch[1],\n","                  'labels':         batch[2],\n","                 }\n","\n","        with torch.no_grad():        \n","            outputs = model(**inputs)     \n","\n","        logits = outputs[1]\n","\n","        logits = logits.detach().cpu().numpy()\n","\n","        label_ids = inputs['labels'].cpu().numpy()\n","\n","        predictions.append(logits)\n","        true_vals.append(label_ids)\n","\n","    predictions = np.concatenate(predictions, axis=0)\n","    true_vals = np.concatenate(true_vals, axis=0)\n","            \n","    return predictions, true_vals"]},{"cell_type":"markdown","metadata":{"id":"mlmoQ6-ZmHoQ"},"source":["**Training durchführen**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":850,"referenced_widgets":["dc975a3a94704ba5abf5b033bb916dc1","9667fd01472c4ad8bd5d06e6190c3aea"]},"id":"NUiZnYiGRQYU","outputId":"608a3d6b-7c5e-4393-99a1-8c723fb31c25"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc975a3a94704ba5abf5b033bb916dc1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9667fd01472c4ad8bd5d06e6190c3aea","version_major":2,"version_minor":0},"text/plain":["Epoch 1:   0%|          | 0/46450 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["training_losses = []\n","valid_losses = []\n","fOnes = []\n","# set initial loss to infinite\n","best_valid_loss = float('inf')\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n","\n","seed_val = 17\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","for epoch in tqdm(range(1, epochs+1)):\n","    \n","    model.train()\n","    \n","    loss_train_total = 0\n","\n","    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n","    for batch in progress_bar:\n","\n","        model.zero_grad()\n","        \n","        batch = tuple(b.to(device) for b in batch)\n","        \n","        inputs = {'input_ids':      batch[0],\n","                  'attention_mask': batch[1],\n","                  'labels':         batch[2],\n","                 }       \n","\n","        outputs = model(**inputs)\n","        \n","        loss = outputs[0]\n","        loss_train_total += loss.item()\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        optimizer.step()\n","        scheduler.step()\n","        \n","        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n","        \n","    tqdm.write(f'\\nEpoch {epoch}')\n","    \n","    loss_train_avg = loss_train_total/len(dataloader_train)            \n","    tqdm.write(f'Training loss: {loss_train_avg}')\n","    training_losses.append(loss_train_avg)\n","    \n","    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n","    val_f1 = f1_score_func(predictions, true_vals)\n","    tqdm.write(f'Validation loss: {val_loss}')\n","    valid_losses.append(val_loss)\n","    \n","    if val_loss < best_valid_loss:\n","        best_valid_loss = val_loss\n","        torch.save(model.state_dict(), '/content/drive/MyDrive/saved_weights_M1_v1.model')  \n","        \n","    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n","    fOnes.append(val_f1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5eCgrU4Nn6XD"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","# line 1 points\n","x1 = range(len(training_losses))\n","y1 = training_losses\n","# plotting the line 1 points \n","plt.plot(x1, y1, label = \"line 1\")\n","# line 2 points\n","x2 = range(len(valid_losses))\n","y2 = valid_losses\n","# plotting the line 2 points \n","plt.plot(x2, y2, label = \"line 2\")\n","plt.xlabel('Epochen')\n","# Set the y axis label of the current axis.\n","plt.ylabel('Training')\n","# Set a title of the current axes.\n","plt.title('Losses')\n","# show a legend on the plot\n","plt.legend()\n","# Display a figure.\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mGfhe0Tpn6XD"},"outputs":[],"source":["# line 1 points\n","x1 = range(len(fOnes))\n","y1 = fOnes\n","# plotting the line 1 points \n","plt.plot(x1, y1, label = \"line 1\")\n","plt.xlabel('Epochen')\n","# Set the y axis label of the current axis.\n","plt.ylabel('F1')\n","# Set a title of the current axes.\n","plt.title('F1 Validation')\n","# show a legend on the plot\n","plt.legend()\n","# Display a figure.\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"3SSIItcW6hoI"},"source":["**Testen**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5cU7EWyMf8Uz"},"outputs":[],"source":["bert_base_model = \"dmis-lab/biobert-base-cased-v1.2\"\n","training_state = '/content/drive/MyDrive/saved_weights_M1_v1.model'\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")\n","\n","model = BertForSequenceClassification.from_pretrained(bert_base_model,\n","                                                      num_labels=len(labels_Input),\n","                                                      output_attentions=False,\n","                                                      output_hidden_states=False)\n","print(\"BFSC as Model loaded....\")\n","\n","model.load_state_dict(torch.load(training_state, map_location=device))\n","print(\"state_dict loaded.....\")\n","\n","#tokenizer = BertTokenizer.from_pretrained(bert_base_model, \n","                                          #output_hidden_states=False,\n","                                          #map_location=device)\n","#print(\"Tokenizer loaded.....\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nFY0vM4af8mj"},"outputs":[],"source":["predictions, true_vals = test(dataloader_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2XcQZ0g6f8hV"},"outputs":[],"source":["val_f1 = f1_score_func(predictions, true_vals)\n","tqdm.write(f'F1 Score (Weighted): {val_f1}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ArFJxeyUf8bw"},"outputs":[],"source":["preds = np.argmax(predictions, axis = 1)\n","print(classification_report(true_vals, preds))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PY9fAHqxf8Kr"},"outputs":[],"source":["sentence = \"Comprehensive care of lower urinary tract infections\"\n","model.eval()\n","\n","input = tokenizer.encode_plus(sentence, add_special_tokens=True, return_tensors = \"pt\")\n","output = model(**input)\n","logits = output.logits\n","soft = torch.nn.Softmax(dim=0)\n","soft_tensor = soft(logits[0])\n","probs = soft_tensor.detach().numpy()\n","#print(probs)\n","probabilities = {}\n","for k, v in labels_Input.items():\n","    probabilities[k] = probs[v[\"index\"]]\n","print(probabilities)\n","print(\"-----------------------------------------------------------------------------------------\")\n"]}],"metadata":{"colab":{"background_execution":"on","machine_shape":"hm","name":" Modell Training M1 v1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":0}